---
pagetitle: "Lesson 27"
title: "Random Forest in R (caret + randomForest) — Titanic Classification"
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = "center",
  message = FALSE,
  warning = FALSE
)
```

# Random Forest on Titanic

A Random Forest is an ensemble of many decision trees that can be used for **classification** and **regression**.
In this lesson we follow the same workflow as the Decision Tree / ML lessons: import → clean → split → fit → evaluate → tune → interpret.

In this lesson we will:
- Import Titanic data from a local CSV
- Clean the dataset (drop columns + fix types)
- Create train/test split
- Train a Random Forest classifier with cross-validation
- Evaluate accuracy + confusion matrix
- Tune `mtry` (number of candidate predictors per split)
- Inspect feature importance

# Step 1: Import the data

```{r}
library(dplyr)

path <- "raw_data/titanic_data.csv"
titanic <- read.csv(path, stringsAsFactors = FALSE)

dim(titanic)
head(titanic, 3)
```

# Step 2: Clean and prepare data

Random Forest (via `randomForest`) can handle factors directly, so we typically do **not** need one-hot encoding like XGBoost.

```{r}
titanic_clean <- titanic |>
  # drop columns that are not useful or require heavy feature engineering
  select(-any_of(c("home.dest", "cabin", "name", "X", "x", "ticket"))) |>
  # remove invalid entries sometimes used in this dataset
  filter(embarked != "?") |>
  mutate(
    pclass = factor(
      pclass,
      levels = c(1, 2, 3),
      labels = c("Upper", "Middle", "Lower")
    ),
    survived = factor(survived, levels = c(0, 1), labels = c("No", "Yes")),
    sex = factor(sex),
    embarked = factor(embarked),
    age = as.numeric(age),
    fare = as.numeric(fare),
    sibsp = as.numeric(sibsp),
    parch = as.numeric(parch)
  ) |>
  na.omit()

glimpse(titanic_clean)
```

# Step 3: Train/test split

```{r}
set.seed(123)

n <- nrow(titanic_clean)
idx_train <- sample.int(n, size = floor(0.8 * n))

train_df <- titanic_clean[idx_train, ]
test_df  <- titanic_clean[-idx_train, ]

c(n_train = nrow(train_df), n_test = nrow(test_df))
prop.table(table(train_df$survived))
prop.table(table(test_df$survived))
```

# Step 4: Train a baseline Random Forest (cross-validation)

We will use `caret::train()` with `method = "rf"`, which fits a Random Forest and tunes `mtry` using resampling.
In `caret`, the tuning grid for `method="rf"` is expected to include **only** `mtry` (while `ntree` is passed as a regular argument, not as a tuning parameter).

```{r}
# install.packages(c("caret", "randomForest", "e1071"))
library(caret)
library(randomForest)
library(e1071)

set.seed(123)

ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE
)

rf_cv <- train(
  survived ~ .,
  data = train_df,
  method = "rf",
  metric = "Accuracy",
  trControl = ctrl,
  tuneLength = 6,    # caret tries multiple mtry values
  ntree = 500,
  importance = TRUE
)

rf_cv
rf_cv$bestTune
```

# Step 5: Predictions

```{r}
pred_class <- predict(rf_cv, newdata = test_df)
head(pred_class)
```

# Step 6: Evaluation (confusion matrix + accuracy)

```{r}
confusionMatrix(pred_class, test_df$survived)
```

# Step 7: Feature importance

The `randomForest` model can report variable importance (e.g., MeanDecreaseAccuracy and MeanDecreaseGini in classification when importance is enabled).

```{r}
# caret-style importance
varimp_caret <- varImp(rf_cv)
varimp_caret
plot(varimp_caret, top = 15)

# randomForest-style importance (from the final fitted model)
rf_final <- rf_cv$finalModel
imp_rf <- importance(rf_final)
head(imp_rf[order(imp_rf[, "MeanDecreaseGini"], decreasing = TRUE), , drop = FALSE], 10)
```

# (Optional) Step 8: Manual tuning grid for mtry

Here is a more explicit tuning grid for `mtry`; note that the grid must have the column `mtry` only.

```{r}
p <- ncol(train_df) - 1  # predictors count (excluding survived)
grid_mtry <- expand.grid(mtry = unique(pmax(1, round(c(1, sqrt(p), p/3, p/2)))))

set.seed(123)
rf_tuned <- train(
  survived ~ .,
  data = train_df,
  method = "rf",
  metric = "Accuracy",
  trControl = ctrl,
  tuneGrid = grid_mtry,
  ntree = 500,
  importance = TRUE
)

rf_tuned
rf_tuned$bestTune
```

Evaluate the tuned model on the test set:

```{r}
pred_class2 <- predict(rf_tuned, newdata = test_df)
confusionMatrix(pred_class2, test_df$survived)
```

# Summary

You learned how to:
- clean Titanic data for Random Forest without one-hot encoding
- train a Random Forest classifier with cross-validation using `caret`
- tune `mtry` and keep `ntree` fixed during training
- evaluate performance using a confusion matrix
- inspect variable importance from the fitted forest
